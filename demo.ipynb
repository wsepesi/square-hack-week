{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nous-hermes-13b.ggmlv3.q4_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" ### Instructions:\n",
    "    Summarize the following query in one precise sentence evaluating what the user is trying to achieve. Eliminate extraneous information and focus on the core of the question.\n",
    "\n",
    "    ### Input:\n",
    "    hello there, is there a way to extend a hold on a user applied via regulator \"create user hold\" ? for more context, credit risk ops team applied a hold on a seller(convene) but the duration is defaulted to 90 days which is not sufficient for this use case. without an option to extend to a custom time, ops team is waiting for the existing hold to expire and then apply a new hold for the next 90 days using reminders which is tedious and error prone. just wanted to check if there is any override that can be done in the backend to extend the hold. thanks  :pray:\n",
    "\n",
    "    ### Response:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/williamsepesi/.cache/gpt4all/nous-hermes-13b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[25483]: Class GGMLMetalClass is implemented in both /Users/williamsepesi/miniconda3/envs/hack/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x108f00208) and /Users/williamsepesi/miniconda3/envs/hack/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x10914c208). One of the two will be used. Which one is undefined.\n",
      "llama.cpp: using Metal\n",
      "llama.cpp: loading model from /Users/williamsepesi/.cache/gpt4all/nous-hermes-13b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 9031.71 MB (+ 1608.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1600.00 MB\n",
      "ggml_metal_init: allocating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: max tensor size =    87.89 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/williamsepesi/miniconda3/envs/hack/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x107c4eab0\n",
      "ggml_metal_init: loaded kernel_mul                            0x107c4ff80\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x107c51350\n",
      "ggml_metal_init: loaded kernel_scale                          0x107c501e0\n",
      "ggml_metal_init: loaded kernel_silu                           0x107c50440\n",
      "ggml_metal_init: loaded kernel_relu                           0x107c52810\n",
      "ggml_metal_init: loaded kernel_gelu                           0x107c52ec0\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x107c53340\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x107c53d20\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x107c543c0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x107c54b80\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x107c553c0\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_k                  0x107c55aa0\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_k                  0x107c55620\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_k                  0x107c56900\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_k                  0x107c57030\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_k                  0x107c57730\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x107c57e70\n",
      "ggml_metal_init: loaded kernel_norm                           0x107c585b0\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x107c58e80\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x107c596f0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x107c59eb0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_k_f32               0x107c5a690\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_k_f32               0x107c5b010\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_k_f32               0x107c5b740\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_k_f32               0x107c5bf50\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_k_f32               0x107c5c730\n",
      "ggml_metal_init: loaded kernel_rope                           0x107c5d230\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x107c5dc60\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x107c5e550\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x107c5eec0\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x107c5f830\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 49152.00 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  6984.06 MB, ( 6984.45 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =  1024.00 MB, ( 8008.45 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1602.00 MB, ( 9610.45 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   512.00 MB, (10122.45 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   512.00 MB, (10634.45 / 49152.00)\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user wants to know if there's a way to extend a hold on a seller applied by credit risk ops team using regulator \"create user hold\" beyond its default duration of 90 days, without having to apply a new hold every time the existing one expires.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..........Par'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector db tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlite import VLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in text as a string from data/priv_guide.txt\n",
    "\n",
    "with open(\"data/priv_guide.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dummy_chunker import naive_chunking\n",
    "\n",
    "chunks = naive_chunking(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: BertTokenizerFast(name_or_path='sentence-transformers/all-MiniLM-L6-v2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n",
      "MPS is available\n",
      "Device: mps\n",
      "Encoded input done torch.Size([84, 74])\n",
      "Encoded input moved to device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0f9c5f19-192e-42de-a360-b08600ffda36',\n",
       " array([[-0.07467156,  0.03449959, -0.01376451, ...,  0.0165997 ,\n",
       "         -0.03030579,  0.03880912],\n",
       "        [-0.09117734, -0.01860103,  0.01233036, ..., -0.03594091,\n",
       "         -0.00058903, -0.01651122],\n",
       "        [-0.01153258, -0.0731879 , -0.05801082, ..., -0.02407446,\n",
       "          0.00460041, -0.01074034],\n",
       "        ...,\n",
       "        [-0.07460977, -0.01030446,  0.02368455, ..., -0.01014081,\n",
       "         -0.06889876, -0.038445  ],\n",
       "        [-0.10408906,  0.04218348, -0.04617474, ..., -0.01245864,\n",
       "          0.02150463,  0.03952773],\n",
       "        [-0.13196625,  0.04160925, -0.00379069, ..., -0.0891984 ,\n",
       "         -0.00083516,  0.04574984]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = VLite()\n",
    "\n",
    "db.memorize(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Device: mps\n",
      "Encoded input done torch.Size([1, 5])\n",
      "Encoded input moved to device\n",
      "[remember] Sims: (1, 84)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Data is usually, but is not always, Personal Data (consult your business unit’s DSL Framework for more specific guidance). The improper processing of Confidential Data may, among other things, result in the exposure of the private data of individuals, subject Block to regulatory penalties, and/or',\n",
       "  'Block, its customers, and/or its employees. Secret Data includes certain types of Personal Data, PCI Data, and Regulated Data (consult your business unit’s DSL Framework for more specific guidance). The improper processing of Secret Data may, among other things, result in the risk of identity theft',\n",
       "  'been anonymized, it is no longer considered Personal Data. Business Data 1 * The minimum DSL for pseudonymized datasets varies. Consult business unit-specific DSL Frameworks for detailed guidance. However, pseudonymized data is always considered Personal Data for purposes of applicable data',\n",
       "  'related to an identifiable person or household. Data is considered Personal Data if it can be used to identify a person, directly or indirectly, including by reference to an identifier such as a name, an identification number, location data, an online identifier, or to one or more factors specific to the',\n",
       "  'Underwriting decisions Pseudonymized Personal Data The processing of Personal Data, including its collection, use, disclosure, retention, and destruction, is governed by a variety of data protection laws, including the European General Data Protection Regulation (GDPR), the California'],\n",
       " array([0.717196  , 0.64569683, 0.62616772, 0.61966894, 0.60656808]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.remember(\"confidential personal data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
