{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils.type_utils import ProcessedData\n",
    "from typing import List, Tuple\n",
    "from vlite import VLite\n",
    "from uuid import uuid4\n",
    "from onboarding_utils.docs_parser.preprocessor import chunker\n",
    "from onboarding_utils.slackparser.ledgertextscraper import get_slack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = \"v1.npz\" # specifify your database path here. further functions either create or use this database\n",
    "db = VLite(collection = DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_SOURCE = \"Ledger/\" # change to your data folder containing Google Docs exported as HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_data_v0 = chunker(DOCS_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_data: List[ProcessedData] = []\n",
    "for key in docs_data_v0:\n",
    "    for item in docs_data_v0[key]:\n",
    "        docs_data.append(ProcessedData(id = str(uuid4()), text = item, metadata = {\"key\": key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_data_v0 = get_slack_data(\"ledger.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_data = [ProcessedData(id = str(uuid4()), text = item, metadata = {\"key\": \"slack\"}) for item in slack_data_v0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = docs_data + slack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest data\n",
    "db.memorize(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
